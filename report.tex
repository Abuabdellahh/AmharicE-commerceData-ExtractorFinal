\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{listings}
\usepackage{color}
\usepackage{float}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{fancyhdr}
\usepackage{titlesec}

\geometry{a4paper, margin=1in}
\titleformat{\section}{\normalfont\Large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesubsection}{1em}{}

\pagestyle{fancy}
\fancyhf{}
\rhead{Amharic E-commerce Data Extractor}
\lhead{10 Academy - W4}
\rfoot{Page \thepage}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                   
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\title{Amharic E-commerce Data Extractor\\Interim Submission Report}
\author{10 Academy - W4}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This report documents the progress of the Amharic E-commerce Data Extractor project, focusing on data collection, preprocessing, and NER model development. The system aims to extract business entities from Amharic e-commerce data collected from Telegram channels, enabling EthioMart to consolidate and analyze e-commerce activities across multiple platforms.
\end{abstract}

\tableofcontents
\newpage

\section{Project Overview}

The Amharic E-commerce Data Extractor project aims to build a system that can:
\begin{itemize}
    \item Collect e-commerce data from multiple Telegram channels
    \item Process and normalize Amharic text
    \item Extract key business entities (products, prices, locations)
    \item Analyze vendor performance
\end{itemize}

\section{Data Collection Pipeline}

\subsection{Telegram Scraper Implementation}
Our system utilizes the Telegram API to collect data from multiple e-commerce channels. Key features include:
\begin{itemize}
    \item Multi-channel support
    \item Message metadata collection (views, forwards, timestamps)
    \item Rate limiting handling
    \item Error logging and recovery
\end{itemize}

\begin{lstlisting}[language=Python, caption=Telegram Scraper Implementation]
async def get_channel_messages(self, channel_username: str, limit: int = 1000):
    messages = []
    try:
        entity = await self.client.get_entity(channel_username)
        async for message in self.client.iter_messages(entity, limit=limit):
            if message.text:
                message_data = {
                    'id': message.id,
                    'text': message.text,
                    'date': message.date.isoformat(),
                    'views': message.views or 0,
                    'forwards': message.forwards or 0,
                    'channel': channel_username
                }
                messages.append(message_data)
    except Exception as e:
        self.logger.error(f"Error fetching messages: {e}")
\end{lstlisting}

\section{Data Preprocessing}

\subsection{Text Normalization}
The text preprocessing pipeline includes:
\begin{itemize}
    \item Amharic-specific tokenization
    \item Unicode normalization
    \item Stopword removal
    \item Entity pattern matching
\end{itemize}

\begin{lstlisting}[language=Python, caption=Text Preprocessing]
def clean_text(self, text: str):
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    
    # Remove URLs
    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
    
    # Normalize Unicode
    text = unicodedata.normalize('NFC', text)
    return text.strip()
\end{lstlisting}

\section{Named Entity Recognition (NER)}

\subsection{Model Implementation}
We have implemented a NER system using XLM-Roberta, fine-tuned for Amharic e-commerce data. The model is capable of identifying:
\begin{itemize}
    \item Product names
    \item Prices in Ethiopian Birr
    \item Location mentions
\end{itemize}

\begin{lstlisting}[language=Python, caption=NER Model Implementation]
def tokenize_and_align_labels(self, examples):
    tokenized_inputs = self.tokenizer(
        examples["tokens"],
        truncation=True,
        is_split_into_words=True,
        padding=True,
        max_length=512
    )
    
    labels = []
    for i, label in enumerate(examples["ner_tags"]):
        word_ids = tokenized_inputs.word_ids(batch_index=i)
        previous_word_idx = None
        label_ids = []
        for word_idx in word_ids:
            if word_idx is None:
                label_ids.append(-100)
            elif word_idx != previous_word_idx:
                label_ids.append(label[word_idx])
            else:
                label_ids.append(label_ids[-1])
        labels.append(label_ids)
    
    tokenized_inputs["labels"] = labels
    return tokenized_inputs
\end{lstlisting}

\section{Vendor Analytics}

\subsection{Performance Metrics}
The vendor analytics engine calculates key metrics including:
\begin{itemize}
    \item Average views per post
    \item Posting frequency (posts per week)
    \item Average price point
    \item Top performing posts
\end{itemize}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Metric} & \textbf{Weight} & \textbf{Normalization} & \textbf{Description} \\ \hline
        Views & 0.5 & 10,000 views & Average views per post \\ \hline
        Frequency & 0.3 & 10 posts/week & Posting frequency \\ \hline
        Price & 0.2 & 10,000 ETB & Average price point \\ \hline
    \end{tabular}
    \caption{Vendor Scorecard Metrics}
\end{table}

\section{Model Interpretability}

We've implemented both SHAP and LIME explanations for model predictions:
\begin{itemize}
    \item SHAP: Global feature importance
    \item LIME: Local prediction explanations
    \item Difficulty case analysis
\end{itemize}

\section{Project Structure}

\begin{figure}[H]
    \centering
    \begin{verbatim}
    amharic-ecommerce-extractor/
    ├── config/              # Configuration files
    │   └── config.yaml      # Project configuration
    ├── src/                 # Source code
    │   ├── data/            # Data processing modules
    │   │   ├── telegram_scraper.py
    │   │   └── text_preprocessor.py
    │   ├── labeling/        # NER labeling modules
    │   │   └── conll_labeler.py
    │   ├── models/          # Model implementation modules
    │   │   ├── ner_model.py
    │   │   ├── model_comparison.py
    │   │   └── model_interpretability.py
    │   └── analytics/       # Vendor analytics modules
    │       └── vendor_analytics.py
    ├── .env.example         # Environment variables template
    ├── .gitignore           # Git ignore file
    ├── LICENSE              # Project license
    ├── Makefile             # Common tasks
    ├── README.md            # Project documentation
    └── requirements.txt     # Python dependencies
    \end{verbatim}
    \caption{Project Directory Structure}
\end{figure}

\section{Next Steps}

\begin{enumerate}
    \item Complete model fine-tuning and evaluation
    \item Implement additional NER models for comparison
    \item Enhance vendor analytics with more metrics
    \item Add error handling and logging improvements
    \item Implement automated testing
\end{enumerate}

\section{Conclusion}

The Amharic E-commerce Data Extractor project has successfully implemented core components for data collection, preprocessing, and NER model development. The system is well-structured and follows best practices for maintainability and scalability. Future work will focus on model optimization and analytics enhancements to better serve EthioMart's business needs.

\end{document}
